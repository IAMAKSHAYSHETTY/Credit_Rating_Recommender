# -*- coding: utf-8 -*-
"""Algo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RqX6LTTeOU8h_xbaD6U3CjumTUxYRpCg
"""

import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve
from sklearn.decomposition import PCA
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('data.csv')
df

df['Marital status'].value_counts().plot.pie(autopct="%.2f%%")

plt.bar(df['Years of education after high school'].unique(), df['Years of education after high school'].value_counts())

x = df.drop(columns='Credit Rating')
y = df['Credit Rating']

y

x = pd.get_dummies(x)

label = LabelEncoder()
y = label.fit_transform(y)

#PCA - Do PCA Graph and explain the same
#pca = PCA(n_components=2)
#z = pca.fit_transform(x)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=0)

mlp = MLPClassifier(alpha=0.0001,hidden_layer_sizes=(20,2),max_iter=1000000,solver='sgd',
                         activation='relu',random_state=1, learning_rate='adaptive', learning_rate_init=0.001)
mlp.fit(x_train,y_train)

y_pred = mlp.predict(x_test)
probability = mlp.predict_proba(x_test)

f1_score(y_test, y_pred)

accuracy_score(y_test, y_pred)

model_precision, model_recall, thresholds = precision_recall_curve(y_test, probability[:, 1])
plt.plot(model_recall, model_precision, marker='.', label='Logit')
plt.plot(model_recall[5], model_precision[5], "ro", label="threshold")
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend()
plt.title('Precision and Recall values for a chosen Threshold')
plt.show()

print("Threshold value = %.4f" % thresholds[6])

def probs_to_prediction(probs, threshold):
    pred=[]
    for x in probs[:,1]:
        if x>threshold:
            pred.append(1)
        else:
            pred.append(0)
    return pred

predictions = probs_to_prediction(probability, 0.4)

f1_score(y_test, predictions)

!pip install eli5

from eli5.sklearn import PermutationImportance
import eli5

x_train = pd.DataFrame(x_train)

feat_perm = PermutationImportance(mlp, random_state=33).fit(x_train, y_train)
eli5.show_weights(feat_perm, feature_names= list(x.columns))

#basic stuffs until split
#xgboost classifier
#feature importance using eli5 or shapley
#Define collateral conditions high amount = yes, low amount = no, medium= highest feature imp.
#pca
#mlp clasifier - with/without pca (dim reduction)
#precision recall curve
#set the threshold
#append based on predictions based on the threshold